{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba83fd76-ad52-4951-8da6-b1f772fc2a29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c9b0d97-e9b2-4090-b6e5-7957d473b8f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 256, 3])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "Image = torch.randn((256,256,3))\n",
    "Scale = torch.tensor([0.5, 1.5, 1])\n",
    "\n",
    "print(Image.shape)\n",
    "print(Scale.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3c82fa6-bd83-47ac-8cd2-119e128925f6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2117, -0.6288,  0.8556],\n",
       "         [ 0.6121, -0.5290, -0.1319],\n",
       "         [ 1.5410,  0.5876,  0.0126],\n",
       "         ...,\n",
       "         [ 0.9640, -0.6629, -1.4636],\n",
       "         [-0.5090,  0.9592, -1.5758],\n",
       "         [-1.0454,  0.8840, -1.0381]],\n",
       "\n",
       "        [[ 1.0821, -0.1667, -0.9645],\n",
       "         [-0.4085,  0.5266,  3.0682],\n",
       "         [-0.1276,  2.2503,  0.3412],\n",
       "         ...,\n",
       "         [ 1.7331, -1.0946, -1.2472],\n",
       "         [-0.5596, -0.4758, -0.7611],\n",
       "         [ 1.5075, -0.7813, -0.8054]],\n",
       "\n",
       "        [[-0.5424, -0.2785, -0.2908],\n",
       "         [ 0.7233, -0.4881, -0.2021],\n",
       "         [ 0.6747, -1.6863, -0.2196],\n",
       "         ...,\n",
       "         [ 0.2239, -0.6971,  0.0433],\n",
       "         [-1.3380,  1.2475,  0.2790],\n",
       "         [-0.6387,  0.7264,  0.4569]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.0215, -1.4290,  0.3826],\n",
       "         [-0.9003, -0.1951,  0.3824],\n",
       "         [ 0.5812,  1.4206,  0.4924],\n",
       "         ...,\n",
       "         [ 0.6551,  0.7912,  0.0711],\n",
       "         [-0.4664, -0.5829, -0.1831],\n",
       "         [ 0.6655,  0.8187, -0.6233]],\n",
       "\n",
       "        [[ 0.4340,  0.5229,  1.8396],\n",
       "         [-0.4410, -0.0388,  1.7474],\n",
       "         [ 0.4182, -0.0763, -1.1821],\n",
       "         ...,\n",
       "         [-0.8470, -0.2589,  0.4252],\n",
       "         [-0.4394, -1.1297, -0.0475],\n",
       "         [ 0.2704,  1.2199,  0.8121]],\n",
       "\n",
       "        [[-1.1238,  0.7673, -1.0159],\n",
       "         [-1.2762, -0.0601,  0.1749],\n",
       "         [-0.9038,  0.8824, -0.0456],\n",
       "         ...,\n",
       "         [ 1.4689, -0.3473,  0.2580],\n",
       "         [-0.7989, -1.1355, -0.8401],\n",
       "         [-0.0741,  0.8105,  0.0063]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2c8e2bc-76ef-4fff-b1e9-dd5a82ffbea9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 8.1892e-01, -2.9871e+00,  2.2357e+00],\n",
       "         [ 1.2608e-01, -2.4307e-02, -8.7867e-01],\n",
       "         [ 3.7081e-01, -2.5708e+00,  2.3502e-01],\n",
       "         ...,\n",
       "         [-7.5301e-02,  1.8917e+00, -2.1095e-01],\n",
       "         [ 1.6802e-01, -1.3388e+00, -3.0984e-01],\n",
       "         [ 1.2113e+00,  1.2925e+00,  7.8873e-01]],\n",
       "\n",
       "        [[ 2.1387e-02,  1.0685e+00, -1.8861e+00],\n",
       "         [-1.3274e-01,  1.7108e+00,  4.3070e-02],\n",
       "         [ 7.1048e-02,  4.9855e-01, -3.6043e-01],\n",
       "         ...,\n",
       "         [-3.3328e-01, -5.9967e-01,  5.1685e-02],\n",
       "         [-9.6964e-02,  1.4161e+00, -1.0738e+00],\n",
       "         [ 3.6488e-01,  5.8684e-01, -6.3443e-02]],\n",
       "\n",
       "        [[-1.9280e-01, -9.0995e-01, -6.4012e-01],\n",
       "         [ 7.3412e-01, -7.6285e-01,  8.2469e-01],\n",
       "         [ 5.0955e-01, -9.9344e-01,  1.3653e-01],\n",
       "         ...,\n",
       "         [-1.7369e-04,  2.4751e+00, -5.5375e-01],\n",
       "         [ 1.2311e+00, -1.9089e-01,  7.1634e-01],\n",
       "         [-2.4004e-01, -8.0624e-01, -1.7641e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 9.9621e-02,  8.3514e-01, -8.0561e-01],\n",
       "         [-2.1441e-01,  6.2374e-01, -1.9170e+00],\n",
       "         [-7.2045e-01,  1.0156e+00,  1.4212e+00],\n",
       "         ...,\n",
       "         [-2.8829e-01, -7.3078e-01, -3.3120e-01],\n",
       "         [-7.9068e-01,  2.2353e+00,  6.4414e-02],\n",
       "         [ 6.5825e-02, -2.3097e+00, -9.6164e-01]],\n",
       "\n",
       "        [[ 2.5856e-01, -9.2734e-02, -1.0487e-01],\n",
       "         [-1.2440e-01,  4.0423e-01,  3.4488e-01],\n",
       "         [ 3.4475e-01, -7.6151e-01, -1.8520e+00],\n",
       "         ...,\n",
       "         [-9.1252e-01,  1.9106e+00,  2.1949e-01],\n",
       "         [ 5.6365e-01, -8.4746e-02,  3.3885e-01],\n",
       "         [-2.6791e-01, -8.1606e-01,  7.2738e-01]],\n",
       "\n",
       "        [[ 7.5234e-01, -9.7911e-02,  2.5597e-01],\n",
       "         [ 2.0497e-01,  1.3169e+00,  5.3783e-01],\n",
       "         [-4.9316e-01, -8.6283e-01,  1.6930e-01],\n",
       "         ...,\n",
       "         [ 6.8643e-01,  1.2245e+00, -1.4722e+00],\n",
       "         [-3.5207e-01,  3.5250e+00, -2.8757e-01],\n",
       "         [ 3.2976e-01,  1.8171e+00, -3.2625e-01]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image*Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b55bb6ef-3d74-4806-877c-206471c4b72b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = torch.arange(20, dtype = float).reshape(5,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0e0ed99-21bf-4bc8-ae30-2abded066b40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.],\n",
       "        [12., 13., 14., 15.],\n",
       "        [16., 17., 18., 19.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e962360-d391-47f5-9fab-50d0dc9ad521",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]], dtype=torch.float64),\n",
       " tensor([ 8.,  9., 10., 11.], dtype=torch.float64))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t, torch.mean(t, axis = 0) # Mean across the rows, that are the first dimension!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc0f03ae-82fc-46bd-b7e7-a18e4606a637",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.5000,  5.5000,  9.5000, 13.5000, 17.5000], dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(t, axis = 1) # Mean across the columns, that are the SECOND dimension!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f59a7537-a85a-4eea-bd2b-e2e2ee0406f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = torch.randn(5, 256, 256, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ff1a7a-870d-47dc-9dec-3b2d732f38e8",
   "metadata": {},
   "source": [
    "Take the mean across the batch (size 5), different images!\n",
    "\n",
    "It will take the mean of the batchs. For example, it will look each individual channel (red, green, blue) and compute the mean of these channels using the different images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "789f8c43-91ea-4bd5-a502-a7155c35dca2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 256, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(t, axis = 0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a83477-69a5-4212-bd9f-6fc33a977081",
   "metadata": {},
   "source": [
    "Take the mean across the color channels. It could be used to get something like the brightness of an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1148594-2ea8-47d7-a47c-db886ba1a985",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 256, 256])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(t, axis = -1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7e6576-6f4c-44ea-91d5-628e8d35ae6c",
   "metadata": {},
   "source": [
    "# Where Pytorch Differs from Numpy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2ca33f6a-81b0-40ea-a73f-c3d162402a3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([[5.,8.],[4.,6.]], requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a2fce1bd-707c-4c40-99f5-e5608c5acf3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 8.],\n",
       "        [4., 6.]], requires_grad=True)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3b675550-95ee-4eff-a758-99706811b83e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = x.pow(3).sum() + x.pow(2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ab2c2c32-bcd0-43c6-8be5-5b7854e6687b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 85., 208.],\n",
       "        [ 56., 120.]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3*x.pow(2) + 2*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ad563f98-f664-46b1-b07e-5022eac75531",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1058., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "884a771b-f8cd-4571-b97c-7527bb24ace1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 85., 208.],\n",
       "        [ 56., 120.]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628317c5-21b2-4be2-a9c9-ad9863031ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
